{
    "hub_infer_url": "http://121.40.228.11:8000/v2/models/vllm_model/generate",
    "generate_config": {
        "stream": false,
        "temperature": 0.6,
        "max_tokens": 4096
    }
}